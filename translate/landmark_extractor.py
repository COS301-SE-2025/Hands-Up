import cv2
import mediapipe as mp
import pandas as pd
import numpy as np
import os
from tqdm import tqdm # For progress bars

# --- Configuration ---
# Path to your processed WLASL 20-words CSV (Generated by wlasl_parser.py)
PROCESSED_DATA_CSV = 'wlasl_20_words_processed.csv' # <-- CHANGED THIS LINE
# Directory to save extracted landmark data
OUTPUT_LANDMARKS_DIR = 'extracted_landmarks'
# Whether to visualize the landmarks during extraction (set to False for faster processing)
VISUALIZE_LANDMARKS = False
# Max videos to process for quick test (set to None to process all from CSV)
MAX_VIDEOS_FOR_TEST = None # Should be None to process the full 20 words


# --- Define the expected number of coordinates for each type of landmark (MOVED TO GLOBAL SCOPE) ---
NUM_POSE_COORDS = 33 * 4  # 33 landmarks * (x, y, z, visibility)
NUM_HAND_COORDS = 21 * 3  # 21 landmarks * (x, y, z)
NUM_FACE_COORDS = 468 * 3 # 468 landmarks * (x, y, z) - approximate, actual can be slightly less if not all are visible/estimated


def extract_landmarks_from_video(video_path, mp_holistic_instance):
    # --- NEW LOGIC FOR HANDLING .npy VS .mp4 ---
    is_npy_file = video_path.lower().endswith('.npy')
    
    if is_npy_file:
        try:
            # If it's an NPY, it's already a landmark array. Load directly.
            landmarks_array = np.load(video_path)
            # Verify shape for NPY files (Optional, but good for robustness)
            if landmarks_array.ndim == 2 and landmarks_array.shape[1] == (NUM_POSE_COORDS + 2*NUM_HAND_COORDS + NUM_FACE_COORDS):
                return landmarks_array
            else:
                print(f"Warning: NPY file {video_path} has unexpected shape {landmarks_array.shape}. Skipping.")
                return None
        except Exception as e:
            print(f"Error loading NPY file {video_path}: {e}. Skipping.")
            return None
    # --- END NEW LOGIC ---

    # Original logic for .mp4 files (MediaPipe processing)
    cap = cv2.VideoCapture(video_path) 
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return None

    frame_landmarks_list = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break 

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False

        results = mp_holistic_instance.process(image)

        if VISUALIZE_LANDMARKS:
            image.flags.writeable = True
            frame_copy = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Use a copy for drawing
            mp.solutions.drawing_utils.draw_landmarks(frame_copy, results.pose_landmarks, mp.solutions.holistic.POSE_CONNECTIONS)
            mp.solutions.drawing_utils.draw_landmarks(frame_copy, results.left_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS)
            mp.solutions.drawing_utils.draw_landmarks(frame_copy, results.right_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS)
            mp.solutions.drawing_utils.draw_landmarks(frame_copy, results.face_landmarks, mp.solutions.holistic.FACEMESH_CONTOURS)
            cv2.imshow('MediaPipe Landmarks', frame_copy)
            if cv2.waitKey(1) & 0xFF == 27:
                break

        # Extract raw landmarks into the flat format
        current_frame_raw_landmarks_flat = np.zeros(NUM_POSE_COORDS + NUM_HAND_COORDS + NUM_HAND_COORDS + NUM_FACE_COORDS, dtype=np.float32)
        current_idx = 0
        
        if results.pose_landmarks:
            pose_lms_flat = []
            for landmark in results.pose_landmarks.landmark:
                pose_lms_flat.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])
            current_frame_raw_landmarks_flat[current_idx : current_idx + len(pose_lms_flat)] = pose_lms_flat
        current_idx += NUM_POSE_COORDS

        if results.left_hand_landmarks:
            lh_lms_flat = []
            for landmark in results.left_hand_landmarks.landmark:
                lh_lms_flat.extend([landmark.x, landmark.y, landmark.z])
            current_frame_raw_landmarks_flat[current_idx : current_idx + len(lh_lms_flat)] = lh_lms_flat
        current_idx += NUM_HAND_COORDS

        if results.right_hand_landmarks:
            rh_lms_flat = []
            for landmark in results.right_hand_landmarks.landmark:
                rh_lms_flat.extend([landmark.x, landmark.y, landmark.z])
            current_frame_raw_landmarks_flat[current_idx : current_idx + len(rh_lms_flat)] = rh_lms_flat
        current_idx += NUM_HAND_COORDS

        if results.face_landmarks:
            face_lms_flat = []
            for landmark in results.face_landmarks.landmark:
                face_lms_flat.extend([landmark.x, landmark.y, landmark.z])
            current_frame_raw_landmarks_flat[current_idx : current_idx + len(face_lms_flat)] = face_lms_flat

        frame_landmarks_list.append(current_frame_raw_landmarks_flat)

    cap.release()
    if VISUALIZE_LANDMARKS:
        cv2.destroyAllWindows()
    
    if frame_landmarks_list:
        return np.array(frame_landmarks_list, dtype=np.float32)
    else:
        return None


if __name__ == "__main__":
    os.makedirs(OUTPUT_LANDMARKS_DIR, exist_ok=True)

    if not os.path.exists(PROCESSED_DATA_CSV):
        print(f"Error: Processed data CSV not found at {PROCESSED_DATA_CSV}. Please run combine_datasets.py first.") # Updated error message
        exit()
    
    df_base = pd.read_csv(PROCESSED_DATA_CSV)
    print(f"Loaded {len(df_base)} video entries from {PROCESSED_DATA_CSV}")

    mp_holistic = mp.solutions.holistic.Holistic(
        static_image_mode=False,
        model_complexity=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )

    processed_count = 0
    skipped_count = 0

    for index, row in tqdm(df_base.iterrows(), total=len(df_base), desc="Extracting Landmarks"):
        if MAX_VIDEOS_FOR_TEST is not None and processed_count >= MAX_VIDEOS_FOR_TEST:
            print(f"Stopping after {MAX_VIDEOS_FOR_TEST} videos for testing.")
            break

        video_path = row['video_path'] # This now can be an MP4 or NPY path
        video_id = row['video_id']
        gloss = row['gloss']

        output_npy_filename = f"{video_id}.npy"
        output_npy_path = os.path.join(OUTPUT_LANDMARKS_DIR, output_npy_filename)

        if os.path.exists(output_npy_path):
            processed_count += 1
            continue

        landmarks_data = extract_landmarks_from_video(video_path, mp_holistic)

        if landmarks_data is not None and landmarks_data.shape[0] > 0:
            np.save(output_npy_path, landmarks_data)
            processed_count += 1
        else:
            print(f"Warning: No valid landmarks extracted for {video_path}. Skipping.")
            skipped_count += 1

    mp_holistic.close()
    print(f"\n--- Landmark Extraction Summary ---")
    print(f"Total videos processed: {processed_count}")
    print(f"Total videos skipped (e.g., no landmarks, already processed): {skipped_count}")
    print(f"Landmark data saved to: {OUTPUT_LANDMARKS_DIR}")

    # --- Test a saved landmark file ---
    if processed_count > 0:
        example_video_id = None
        # Find an example NPY that was just processed or already existed
        for _, row in df_base.iterrows():
            temp_output_npy_path = os.path.join(OUTPUT_LANDMARKS_DIR, f"{row['video_id']}.npy")
            if os.path.exists(temp_output_npy_path):
                example_video_id = row['video_id']
                break
        
        if example_video_id:
            example_npy_path = os.path.join(OUTPUT_LANDMARKS_DIR, f"{example_video_id}.npy")
            loaded_landmarks = np.load(example_npy_path)
            print(f"\nSuccessfully loaded example landmark file: {example_npy_path}")
            print(f"Shape of loaded landmarks (frames, total_coords): {loaded_landmarks.shape}")
            print(f"First few values of the first frame's landmarks:\n{loaded_landmarks[0, :10]}")
            
            expected_total_coords = NUM_POSE_COORDS + NUM_HAND_COORDS + NUM_HAND_COORDS + NUM_FACE_COORDS
            print(f"Expected total coordinates per frame: {expected_total_coords}")
            if loaded_landmarks.shape[1] != expected_total_coords:
                print(f"WARNING: Loaded landmark dimension {loaded_landmarks.shape[1]} does not match expected {expected_total_coords}.")

        else:
            print("\nNo videos were processed to test landmark saving, or no .npy files were found in the output directory.")
    else:
        print("\nNo videos were processed to test landmark saving.")